{
    "RandomSearchCV_BestParams": {
        "tol": 0.00905480537684823,
        "optimizer": "sgd",
        "learning_rate_init": 0.006618351933474228,
        "learning_rate": "constant",
        "hidden_layer_sizes": [
            24,
            4,
            5,
            14,
            4,
            9,
            2,
            17,
            22,
            12,
            5
        ],
        "epochs": 1000,
        "alpha": 0.03965251394824704,
        "activation": "relu"
    },
    "feature_importances": {
        "threshold": {
            "importances_mean": [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            "importances_std": [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            "importances": [
                [
                    0.0
                ],
                [
                    0.0
                ],
                [
                    0.0
                ],
                [
                    0.0
                ],
                [
                    0.0
                ]
            ]
        },
        "distance": {
            "importances_mean": [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            "importances_std": [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            "importances": [
                [
                    0.0
                ],
                [
                    0.0
                ],
                [
                    0.0
                ],
                [
                    0.0
                ],
                [
                    0.0
                ]
            ]
        },
        "exact_accuracy": {
            "importances_mean": [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            "importances_std": [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            "importances": [
                [
                    0.0
                ],
                [
                    0.0
                ],
                [
                    0.0
                ],
                [
                    0.0
                ],
                [
                    0.0
                ]
            ]
        },
        "balanced_accuracy": {
            "importances_mean": [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            "importances_std": [
                0.0,
                0.0,
                0.0,
                0.0,
                0.0
            ],
            "importances": [
                [
                    0.0
                ],
                [
                    0.0
                ],
                [
                    0.0
                ],
                [
                    0.0
                ],
                [
                    0.0
                ]
            ]
        }
    },
    "feature_names_in": [
        "Epithelialisering",
        "Kontraktion",
        "Eksudat",
        "Eksudattype",
        "Infektionsniveau"
    ],
    "train_accuracies": {
        "threshold": 0.8208955223880597,
        "distance": 0.8204217010187125,
        "exact_accuracy": 0.12437810945273632,
        "balanced_accuracy": 0.0
    },
    "train_precision": 0.12437810945273632,
    "train_recall": 0.12437810945273632,
    "test_accuracies": {
        "threshold": 0.8278145695364238,
        "distance": 0.8247871333964037,
        "exact_accuracy": 0.12582781456953643,
        "balanced_accuracy": 0.0
    },
    "test_precision": 0.12582781456953643,
    "test_recall": 0.12582781456953643,
    "train_pred_y": [
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5
    ],
    "test_pred_y": [
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5,
        5
    ],
    "pipeline_config": {
        "General": {
            "loglevel": "INFO",
            "n_jobs": -1,
            "write_figure_to_disk": true,
            "UseCleaner": true,
            "UseStatisticalFeatureSelector": true,
            "UseTransformer": false,
            "UseOutlierRemoval": false,
            "UseContinuousFeatures": false
        },
        "DataPreprocessing": {
            "Cleaning": {
                "DeleteNanColumns": true,
                "DeleteNonfeatures": true,
                "DeleteMissingValues": false,
                "DeleteUndeterminedValue": false,
                "RemoveNaNAmount": true,
                "RemoveNaNAmountArgs": 3,
                "FillNan": true,
                "ShowNan": true
            },
            "OutlierAnalysis": {
                "OutlierRemovalMethod": "ODIN",
                "odinParams": {
                    "k": 30,
                    "T": 0
                },
                "avfParams": {
                    "k": 10
                }
            },
            "Transformer": {
                "Discretization": {
                    "DiscretizeColumns": [
                        "S\u00e5rrand (cm)",
                        "Midte (cm)"
                    ],
                    "DiscretizeMethod": "NONE",
                    "ChiMergeMaximumMergeThreshold": {
                        "S\u00e5rrand (cm)": "inf",
                        "Midte (cm)": "inf"
                    },
                    "DiscretizeDesiredIntervals": {
                        "S\u00e5rrand (cm)": 5,
                        "Midte (cm)": 5
                    }
                },
                "OneHotEncoding": {
                    "UseOneHotEncoding": true,
                    "OneHotEncodeLabels": [
                        "Eksudattype"
                    ]
                },
                "Imputation": {
                    "ImputationMethod": "MODE",
                    "KNN_NearestNeighbors": 5,
                    "KNN_DistanceMetric": "MATRIX"
                },
                "Normalisation": {
                    "NormalisationMethod": "MIN_MAX",
                    "NormaliseFeatures": [
                        "Niveau s\u00e5rv\u00e6v",
                        "S\u00e5rskorpe"
                    ]
                }
            },
            "StatisticalFeatureSelection": {
                "score_function": "CHI2",
                "MutualInfoClassifArgs": {
                    "discrete_features": true,
                    "n_neighbors": 3,
                    "random_state": 12
                },
                "GenericUnivariateSelect": true,
                "GenericUnivariateSelectArgs": {
                    "mode": "PERCENTILE",
                    "param": 50
                }
            }
        },
        "ModelSelection": {
            "model": "NEURAL_NETWORK",
            "DecisionTree": {
                "min_weight_fraction_leaf": 0.0,
                "min_samples_split": 6,
                "min_samples_leaf": 7,
                "min_impurity_decrease": 0.0,
                "max_leaf_nodes": 22,
                "max_features": "sqrt",
                "max_depth": 10,
                "criterion": "gini",
                "ccp_alpha": 0.0,
                "random_state": 42
            },
            "RandomForest": {
                "n_estimators": 100,
                "bootstrap": true,
                "oob_score": false,
                "random_state": 53,
                "max_samples": null
            },
            "CategoricalNaiveBayes": {
                "min_categories": 101
            },
            "NeuralNetwork": {
                "hidden_layer_sizes": [
                    10,
                    10
                ],
                "activation": "logistic",
                "solver": "sgd",
                "learning_rate": "constant",
                "learning_rate_init": 0.001,
                "batch_size": 500,
                "alpha": 0.0001,
                "max_iter": 1000,
                "tol": 0.0001,
                "random_state": 678
            }
        },
        "CrossValidationSelection": {
            "cross_validator": "STRATIFIED_KFOLD",
            "StratifiedKFold": {
                "n_splits": 5,
                "shuffle": true,
                "random_state": 177
            }
        },
        "ModelTraining": {
            "training_method": "RANDOM_SEARCH",
            "score_functions": [
                "ALL"
            ],
            "score_function_params": {
                "threshold": 20
            },
            "score_function_weights": {
                "threshold": 0.8,
                "distance": 0.9,
                "exact_accuracy": 1,
                "balanced_accuracy": 1.1
            },
            "train_test_split": {
                "random_state": 111,
                "train_size": 0.8
            },
            "PermutationFeatureImportance": {
                "n_repeats": 1,
                "random_state": 298
            },
            "RFECV": {
                "min_features_to_select": 1,
                "step": 1
            },
            "RandomizedSearchCV": {
                "n_iter": 120,
                "random_state": 378
            },
            "GridSearchCV": {
                "return_train_score": false,
                "refit": "exact_accuracy",
                "verbose": 1
            }
        },
        "ModelEvaluation": {
            "print_model_report": true,
            "plot_confusion_matrix": true,
            "plot_roc_curves": true,
            "plot_feature_importance": true,
            "plot_tree": true,
            "plot_decision_boundary": false
        }
    },
    "grid_config": {
        "ParamGrid": {
            "ParamGridDecisionTree": {
                "criterion": [
                    "log_loss"
                ],
                "max_depth": {
                    "start": 8,
                    "stop": 9,
                    "step": 5
                },
                "min_samples_split": {
                    "start": 7,
                    "stop": 8,
                    "step": 5
                },
                "min_samples_leaf": {
                    "start": 3,
                    "stop": 4,
                    "step": 5
                },
                "min_weight_fraction_leaf": {
                    "start": 0.0,
                    "stop": 0.01,
                    "step": 0.1
                },
                "max_features": [
                    "sqrt"
                ],
                "max_leaf_nodes": {
                    "start": 50,
                    "stop": 51,
                    "step": 5
                },
                "min_impurity_decrease": {
                    "start": 0.0,
                    "stop": 0.01,
                    "step": 0.3
                },
                "ccp_alpha": {
                    "start": 0.0,
                    "stop": 0.01,
                    "step": 0.1
                }
            },
            "ParamGridRandomForest": {
                "n_estimators": {
                    "start": 100,
                    "stop": 2000,
                    "step": 100
                },
                "bootstrap": [
                    true
                ],
                "oob_score": [
                    false
                ],
                "max_samples": {
                    "start": 10,
                    "stop": 1000,
                    "step": 100
                }
            },
            "ParamGridCategoricalNaiveBayes": {
                "min_categories": [
                    101
                ]
            },
            "ParamGridNeuralNetwork": {
                "hidden_layer_sizes": {
                    "layers": {
                        "start": 1,
                        "stop": 15,
                        "step": 2
                    },
                    "layer_size": {
                        "start": 2,
                        "stop": 25,
                        "step": 3
                    }
                },
                "activation": [
                    "relu",
                    "tanh",
                    "logistic"
                ],
                "solver": [
                    "sgd",
                    "adam"
                ],
                "learning_rate": [
                    "constant"
                ],
                "learning_rate_init": {
                    "start": 0.001,
                    "stop": 0.01,
                    "step": 0.005
                },
                "alpha": {
                    "start": 0.001,
                    "stop": 0.5,
                    "step": 0.01
                },
                "max_iter": {
                    "start": 1000,
                    "stop": 1001,
                    "step": 100
                },
                "tol": {
                    "start": 0.0001,
                    "stop": 0.001,
                    "step": 0.1
                }
            }
        },
        "RandomParamGrid": {
            "RandomParamGridDecisionTree": {
                "criterion": [
                    "gini",
                    "log_loss"
                ],
                "max_depth": {
                    "dist": "RANDINT",
                    "dist_params": {
                        "low": 2,
                        "high": 50,
                        "size": 100
                    }
                },
                "min_samples_split": {
                    "dist": "RANDINT",
                    "dist_params": {
                        "low": 2,
                        "high": 40,
                        "size": 100
                    }
                },
                "min_samples_leaf": {
                    "dist": "RANDINT",
                    "dist_params": {
                        "low": 1,
                        "high": 30,
                        "size": 100
                    }
                },
                "min_weight_fraction_leaf": {
                    "dist": "RANDFLOAT",
                    "dist_params": {
                        "low": 0.0,
                        "high": 1.0,
                        "size": 100
                    }
                },
                "max_features": [
                    "sqrt",
                    "log2"
                ],
                "max_leaf_nodes": {
                    "dist": "RANDINT",
                    "dist_params": {
                        "low": 2,
                        "high": 100,
                        "size": 100
                    }
                },
                "min_impurity_decrease": {
                    "dist": "RANDFLOAT",
                    "dist_params": {
                        "low": 0.0,
                        "high": 0.3,
                        "size": 100
                    }
                },
                "ccp_alpha": {
                    "dist": "RANDFLOAT",
                    "dist_params": {
                        "low": 0.0,
                        "high": 0.8,
                        "size": 50
                    }
                }
            },
            "RandomParamGridRandomForest": {
                "n_estimators": {
                    "dist": "RANDINT",
                    "dist_params": {
                        "low": 50,
                        "high": 5000,
                        "size": 200
                    }
                },
                "bootstrap": [
                    true
                ],
                "oob_score": [
                    false
                ],
                "max_samples": {
                    "dist": "RANDINT",
                    "dist_params": {
                        "low": 10,
                        "high": 1500,
                        "size": 100
                    }
                }
            },
            "RandomParamGridCategoricalNaiveBayes": {
                "min_categories": [
                    101
                ]
            },
            "RandomParamGridNeuralNetwork": {
                "hidden_layer_sizes": {
                    "layers": {
                        "start": 1,
                        "stop": 15,
                        "step": 2
                    },
                    "layer_size": {
                        "low": 2,
                        "high": 25,
                        "size": 100
                    }
                },
                "activation": [
                    "relu",
                    "tanh",
                    "logistic"
                ],
                "solver": [
                    "sgd",
                    "adam"
                ],
                "learning_rate": [
                    "constant"
                ],
                "learning_rate_init": {
                    "dist": "RANDFLOAT",
                    "dist_params": {
                        "low": 0.001,
                        "high": 0.01,
                        "size": 500
                    }
                },
                "alpha": {
                    "dist": "RANDFLOAT",
                    "dist_params": {
                        "low": 0.001,
                        "high": 0.5,
                        "size": 500
                    }
                },
                "max_iter": [
                    1000
                ],
                "tol": {
                    "dist": "RANDFLOAT",
                    "dist_params": {
                        "low": 0.0001,
                        "high": 0.01,
                        "size": 1
                    }
                }
            }
        }
    }
}